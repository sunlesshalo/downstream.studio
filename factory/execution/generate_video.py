#!/usr/bin/env python3
"""Generate video from image using Replicate API (Minimax Hailuo or Kling)."""

import os
import sys
import argparse
import subprocess
import urllib.request
import time
from pathlib import Path
from datetime import datetime
from concurrent.futures import ThreadPoolExecutor, as_completed
from dotenv import load_dotenv

# Load environment variables from project root
project_root = Path(__file__).parent.parent.parent  # pipeline/execution -> pipeline -> project root
load_dotenv(project_root / ".env")


def add_video_ai_metadata(video_path: str, model_name: str = "Replicate") -> bool:
    """Add AI-generated metadata to video for EU AI Act compliance.

    Uses ffmpeg to add metadata tags to video file.
    """
    try:
        # Create temp output path
        temp_path = video_path + ".temp.mp4"

        # Metadata to add
        metadata = {
            "comment": "AI-Generated: true",
            "artist": f"DownStream AI ({model_name})",
            "copyright": "Generated by AI - DownStream (downstream.ink)",
            "description": "This video was generated using artificial intelligence. EU AI Act Disclosure.",
        }

        # Build ffmpeg command
        cmd = ["ffmpeg", "-i", video_path, "-y", "-c", "copy"]
        for key, value in metadata.items():
            cmd.extend(["-metadata", f"{key}={value}"])
        cmd.append(temp_path)

        result = subprocess.run(cmd, capture_output=True, text=True)
        if result.returncode == 0:
            # Replace original with metadata version
            os.replace(temp_path, video_path)
            return True
        else:
            # Clean up temp file if exists
            if os.path.exists(temp_path):
                os.remove(temp_path)
            return False
    except Exception as e:
        print(f"Warning: Could not add video metadata: {e}")
        return False


def add_frame_ai_metadata(frame_path: str, model_name: str = "Replicate") -> bool:
    """Add AI-generated metadata to extracted frame for EU AI Act compliance."""
    try:
        from PIL import Image, PngImagePlugin

        if frame_path.lower().endswith(('.png', '.webp')):
            img = Image.open(frame_path)
            metadata = PngImagePlugin.PngInfo()
            metadata.add_text("AI-Generated", "true")
            metadata.add_text("AI-Generator", model_name)
            metadata.add_text("AI-Generator-Provider", "DownStream (downstream.ink)")
            metadata.add_text("Generation-Date", datetime.utcnow().isoformat())
            metadata.add_text("EU-AI-Act-Disclosure", "This image was extracted from AI-generated video")
            img.save(frame_path, pnginfo=metadata)
            return True
    except Exception as e:
        # Don't fail extraction if metadata fails
        pass
    return False

# Model configurations
MODELS = {
    "minimax": {
        "id": "minimax/video-01",
        "name": "Minimax Hailuo",
        "cost": "~$0.50",
        "supports_image": True,
    },
    "kling-v2.1": {
        "id": "kwaivgi/kling-v2.1",
        "name": "Kling v2.1 Standard",
        "cost": "~$0.25 (5s) / ~$0.50 (10s)",
        "supports_image": True,
        "mode": "standard",  # 720p @ 24fps
    },
    "kling-v2.1-pro": {
        "id": "kwaivgi/kling-v2.1",
        "name": "Kling v2.1 Pro",
        "cost": "~$0.45 (5s) / ~$0.90 (10s)",
        "supports_image": True,
        "mode": "pro",  # 1080p @ 24fps
    },
    "kling": {
        "id": "kling-ai/kling-v2.5-pro",
        "name": "Kling v2.5 Pro",
        "cost": "~$0.50-1.00",
        "supports_image": True,
    },
    "kling-turbo": {
        "id": "kling-ai/kling-v2.5-turbo",
        "name": "Kling v2.5 Turbo",
        "cost": "~$0.25-0.50",
        "supports_image": True,
    },
}


def generate_video(
    image_path: str,
    prompt: str,
    output_path: str,
    model: str = "minimax",
    duration: int = 5,
) -> str | None:
    """Generate video from image using Replicate."""
    
    api_token = os.getenv("REPLICATE_API_TOKEN")
    if not api_token:
        print("Error: REPLICATE_API_TOKEN not found in .env file")
        print("Get your token at: https://replicate.com/account/api-tokens")
        sys.exit(1)
    
    try:
        import replicate
    except ImportError:
        print("Error: replicate package not installed")
        print("Install with: pip install replicate")
        sys.exit(1)
    
    if model not in MODELS:
        print(f"Error: Unknown model '{model}'")
        print(f"Available models: {', '.join(MODELS.keys())}")
        sys.exit(1)
    
    model_config = MODELS[model]
    print(f"Generating video with {model_config['name']}...")
    print(f"Estimated cost: {model_config['cost']}")
    print(f"Image: {image_path}")
    print(f"Prompt: {prompt[:80]}...")
    
    image_file = None
    try:
        # Open image file (Replicate handles file objects directly)
        image_file = open(image_path, "rb")

        # Prepare input based on model
        if model == "minimax":
            input_params = {
                "prompt": prompt,
                "first_frame_image": image_file,
            }
        elif model.startswith("kling-v2.1"):
            # Kling v2.1 uses different parameter names
            input_params = {
                "prompt": prompt,
                "start_image": image_file,
                "duration": duration,
                "mode": model_config.get("mode", "standard"),
            }
        else:  # Kling v2.5 models
            input_params = {
                "prompt": prompt,
                "image": image_file,
                "duration": duration,
            }

        print("Creating prediction (async)...")

        # Use async prediction API instead of run() to avoid timeout issues
        prediction = replicate.predictions.create(
            model=model_config["id"],
            input=input_params,
        )
        print(f"Prediction ID: {prediction.id}")
        print(f"Status: {prediction.status}")

        # Close file after upload
        image_file.close()
        image_file = None

        # Poll for completion
        poll_interval = 5  # seconds
        max_wait = 600  # 10 minutes max
        elapsed = 0

        while prediction.status not in ["succeeded", "failed", "canceled"]:
            time.sleep(poll_interval)
            elapsed += poll_interval
            prediction.reload()
            print(f"  Status: {prediction.status} ({elapsed}s)")

            if elapsed >= max_wait:
                print("✗ Timeout waiting for video generation")
                return None

        if prediction.status != "succeeded":
            print(f"✗ Prediction failed: {prediction.error}")
            return None

        # Get video URL from output
        video_url = prediction.output
        if isinstance(video_url, list):
            video_url = video_url[0]

        # Download the video
        print(f"Downloading video...")
        Path(output_path).parent.mkdir(parents=True, exist_ok=True)
        urllib.request.urlretrieve(video_url, output_path)

        print(f"✓ Video saved to: {output_path}")

        # Add AI-generated metadata for EU AI Act compliance
        if add_video_ai_metadata(output_path, model_config['name']):
            print(f"✓ AI metadata added to video")

        return output_path

    except Exception as e:
        print(f"✗ Error generating video: {e}")
        import traceback
        traceback.print_exc()
        return None
    finally:
        # Close the image file if it was opened
        if image_file is not None:
            image_file.close()


def convert_png_to_webp(png_path: str) -> bool:
    """Convert a single PNG file to webp format."""
    try:
        from PIL import Image
        webp_path = png_path.replace('.png', '.webp')
        img = Image.open(png_path)
        img.save(webp_path, 'WEBP', quality=85)
        os.remove(png_path)  # Delete PNG after conversion
        return True
    except Exception as e:
        return False


def extract_frames(
    video_path: str,
    output_dir: str,
    fps: int = None,
    format: str = "webp",
) -> int:
    """Extract frames from video using ffmpeg.

    For webp format: extracts as PNG first, then converts to webp.
    This is because ffmpeg's webp encoder creates animated webp files,
    not individual frame files.
    """

    # Check if ffmpeg is available
    try:
        subprocess.run(["ffmpeg", "-version"], capture_output=True, check=True)
    except (subprocess.CalledProcessError, FileNotFoundError):
        print("Error: ffmpeg not found. Install with: brew install ffmpeg")
        sys.exit(1)

    Path(output_dir).mkdir(parents=True, exist_ok=True)

    # For webp, we need to extract as PNG first then convert
    # ffmpeg's webp encoder creates animated webp, not individual frames
    extract_format = "png" if format == "webp" else format

    # Build ffmpeg command
    cmd = ["ffmpeg", "-i", video_path, "-y"]

    if fps:
        cmd.extend(["-vf", f"fps={fps}"])

    # Output pattern
    output_pattern = str(Path(output_dir) / f"frame_%04d.{extract_format}")
    cmd.append(output_pattern)

    print(f"Extracting frames to {output_dir}...")

    try:
        result = subprocess.run(cmd, capture_output=True, text=True)
        if result.returncode != 0:
            print(f"ffmpeg error: {result.stderr}")
            return 0

        # Count extracted frames
        frames = list(Path(output_dir).glob(f"frame_*.{extract_format}"))
        print(f"✓ Extracted {len(frames)} frames")

        # Convert PNG to webp if needed
        if format == "webp" and extract_format == "png":
            print(f"Converting {len(frames)} frames to webp...")
            converted = 0
            with ThreadPoolExecutor(max_workers=8) as executor:
                futures = {executor.submit(convert_png_to_webp, str(frame)): frame for frame in frames}
                for future in as_completed(futures):
                    if future.result():
                        converted += 1
            print(f"✓ Converted {converted} frames to webp")
            # Update frames list to webp files
            frames = list(Path(output_dir).glob("frame_*.webp"))

        # Add AI metadata to frames in parallel for EU AI Act compliance
        # Use ThreadPoolExecutor since this is I/O bound (file operations)
        if frames:
            metadata_count = 0
            with ThreadPoolExecutor(max_workers=8) as executor:
                futures = {executor.submit(add_frame_ai_metadata, str(frame)): frame for frame in frames}
                for future in as_completed(futures):
                    if future.result():
                        metadata_count += 1
            if metadata_count > 0:
                print(f"✓ AI metadata added to {metadata_count} frames")

        return len(frames)

    except Exception as e:
        print(f"Error extracting frames: {e}")
        return 0


def get_video_duration(video_path: str) -> float:
    """Get video duration in seconds using ffprobe.

    Returns:
        Duration in seconds as float.

    Raises:
        ValueError: If ffprobe fails or returns invalid output.
    """
    cmd = [
        'ffprobe', '-v', 'error',
        '-show_entries', 'format=duration',
        '-of', 'default=noprint_wrappers=1:nokey=1',
        video_path
    ]
    result = subprocess.run(cmd, capture_output=True, text=True)
    if result.returncode != 0:
        raise ValueError(f"ffprobe failed: {result.stderr}")
    try:
        return float(result.stdout.strip())
    except ValueError:
        raise ValueError(f"Invalid duration from ffprobe: {result.stdout}")


def extract_frames_dual(
    video_path: str,
    output_dir_base: str,
    segment_id: int,
    high_frames: int = 140,
    perf_frames: int = 40,
    format: str = "webp"
) -> dict:
    """Extract frames in two quality tiers from a video.

    Creates two directories:
    - {output_dir_base}/frames/{segment_id}/ - high quality (140 frames default)
    - {output_dir_base}/frames-perf/{segment_id}/ - performance (40 frames default)

    FPS is calculated as target_frames / video_duration to ensure
    the correct number of frames regardless of video length.

    Args:
        video_path: Path to the source video file.
        output_dir_base: Base directory (e.g., stream's public folder).
        segment_id: Segment number for subdirectory naming.
        high_frames: Target frame count for high quality tier (default 140).
        perf_frames: Target frame count for performance tier (default 40).
        format: Output format for frames (default webp).

    Returns:
        Dict with frame counts: {"high": int, "perf": int}
    """
    # Get video duration to calculate fps
    duration = get_video_duration(video_path)
    print(f"Video duration: {duration:.2f}s")

    results = {}
    base_path = Path(output_dir_base)

    # High quality tier
    high_dir = base_path / "frames" / str(segment_id)
    high_fps = high_frames / duration
    print(f"\nExtracting high-quality tier ({high_frames} frames @ {high_fps:.2f} fps)...")
    results["high"] = extract_frames(
        video_path=video_path,
        output_dir=str(high_dir),
        fps=high_fps,
        format=format
    )

    # Performance tier
    perf_dir = base_path / "frames-perf" / str(segment_id)
    perf_fps = perf_frames / duration
    print(f"\nExtracting performance tier ({perf_frames} frames @ {perf_fps:.2f} fps)...")
    results["perf"] = extract_frames(
        video_path=video_path,
        output_dir=str(perf_dir),
        fps=perf_fps,
        format=format
    )

    print(f"\n✓ Dual extraction complete: {results['high']} high, {results['perf']} perf frames")
    return results


def main():
    parser = argparse.ArgumentParser(
        description="Generate video from image for downstream streams"
    )
    parser.add_argument(
        "--image", "-i",
        type=str,
        required=True,
        help="Path to source image"
    )
    parser.add_argument(
        "--prompt", "-p",
        type=str,
        required=True,
        help="Motion/animation prompt"
    )
    parser.add_argument(
        "--output", "-o",
        type=str,
        help="Output video path"
    )
    parser.add_argument(
        "--model", "-m",
        type=str,
        default="kling-v2.1",
        choices=list(MODELS.keys()),
        help="Model to use (default: kling-v2.1)"
    )
    parser.add_argument(
        "--duration", "-d",
        type=int,
        default=5,
        help="Video duration in seconds (default: 5)"
    )
    parser.add_argument(
        "--stream", "-n",
        type=str,
        help="Stream name for auto path generation"
    )
    parser.add_argument(
        "--segment", "-s",
        type=int,
        help="Segment number for auto path generation"
    )
    parser.add_argument(
        "--extract-frames",
        action="store_true",
        help="Extract frames after generating video"
    )
    parser.add_argument(
        "--frames-dir",
        type=str,
        help="Directory for extracted frames"
    )
    parser.add_argument(
        "--fps",
        type=int,
        default=None,
        help="FPS for frame extraction (default: original)"
    )
    parser.add_argument(
        "--list-models",
        action="store_true",
        help="List available models and exit"
    )
    
    args = parser.parse_args()
    
    if args.list_models:
        print("Available models:")
        for key, config in MODELS.items():
            print(f"  {key}: {config['name']} ({config['cost']})")
        return
    
    # Determine output path
    if args.output:
        output_path = args.output
    elif args.stream and args.segment:
        output_path = str(
            project_root / f"streams/{args.stream}/videos/segment_{args.segment}.mp4"
        )
    else:
        output_path = str(project_root / "execution/generated_video.mp4")
    
    # Generate video
    video_path = generate_video(
        image_path=args.image,
        prompt=args.prompt,
        output_path=output_path,
        model=args.model,
        duration=args.duration,
    )
    
    if not video_path:
        sys.exit(1)
    
    # Extract frames if requested
    if args.extract_frames:
        if args.frames_dir:
            frames_dir = args.frames_dir
        elif args.stream and args.segment:
            frames_dir = str(
                project_root / f"streams/{args.stream}/public/frames/{args.segment}"
            )
        else:
            frames_dir = str(Path(video_path).parent / "frames")
        
        frame_count = extract_frames(
            video_path=video_path,
            output_dir=frames_dir,
            fps=args.fps,
        )
        
        if frame_count > 0:
            print(f"\n✓ Complete! {frame_count} frames ready for StreamEngine")


if __name__ == "__main__":
    main()
